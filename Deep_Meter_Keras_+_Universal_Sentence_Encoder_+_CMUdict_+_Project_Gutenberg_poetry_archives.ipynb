{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Meter: Keras + Universal Sentence Encoder + CMUdict + Project Gutenberg poetry archives",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "co7MV6sX7Xto",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# [Keras + Universal Sentence Encoder = Deep Meter](https://www.dlology.com/blog/keras-meets-universal-sentence-encoder-transfer-learning-for-text-data/) "
      ]
    },
    {
      "metadata": {
        "id": "eAVQGidpL8v5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook creates an autoencoder using the Universal Sentence Encoder. The autoencoder output is CMUdict syllables. The dataset is that subset of Allison Parrish's Project Gutenberg poetry archive which happens to scan in iambic pentameter.\n",
        "\n",
        "The notebook is based on Chengwei Zhang's example of wrapping the USE inside a larger tensorflow model saves to a Keras model (without save the USE itself in the TF model).\n",
        "\n",
        "The Universal Sentence Encoder makes getting sentence level embeddings as easy as it has historically been to lookup the embeddings for individual words. The sentence embeddings can then be trivially used to compute sentence level meaning similarity as well as to enable better performance on downstream classification tasks using less supervised training data.\n",
        "\n",
        "Since there are 10 one-hot values for 10 sets of 6k syllables, this is \"multi-label classification\"\n",
        "Changes for multi-label classification:\n",
        "sigmoid activation instead of softmax\n",
        "binary_crossentropy\n",
        "\n",
        "Text format is tab-separated, 2 columns: first text, second multi-level\n",
        "array of syllables:\n"
      ]
    },
    {
      "metadata": {
        "id": "pOTzp8O36CyQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Getting Started\n",
        "\n",
        "This section sets up the environment for access to the Universal Sentence Encoder on TF Hub and provides examples of applying the encoder to words, sentences, and paragraphs."
      ]
    },
    {
      "metadata": {
        "id": "lVjNK8shFKOC",
        "colab_type": "code",
        "outputId": "e36ed535-4bd6-4f11-b018-726f0b36ff35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        }
      },
      "cell_type": "code",
      "source": [
        "# Install the latest Tensorflow version.\n",
        "!pip3 install --quiet \"tensorflow>=1.7\"\n",
        "# Install TF-Hub.\n",
        "!pip3 install --quiet tensorflow-hub\n",
        "%cd /content\n",
        "!git clone https://github.com/LanceNorskog/deep_meter || true\n",
        "%cd deep_meter\n",
        "!git pull\n",
        "# could not figure out how to read gzipped files as text!\n",
        "!gunzip -qf blobs/*.gz || true\n",
        "!gunzip -qf prepped_data/*.gz || true"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "fatal: destination path 'deep_meter' already exists and is not an empty directory.\n",
            "/content/deep_meter\n",
            "Already up to date.\n",
            "gzip: blobs/*.gz: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MSeY-MUQo2Ha",
        "colab_type": "code",
        "outputId": "45746e1c-1544-4f11-8274-ef5f1cd4f60e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# boilerplate from base notebook\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns\n",
        "import keras.layers as layers\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "np.random.seed(10)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "feBc_8Y-pt6F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# github deep_meter code\n",
        "import utils\n",
        "# should not need this to use utils.flatten but is true anyway?\n",
        "from itertools import chain\n",
        "import subprocess\n",
        "import syllables\n",
        "# misc for this notebook\n",
        "from ast import literal_eval\n",
        "\n",
        "import scipy\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zwty8Z6mAkdV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q8F4LNGFqOiq",
        "colab_type": "code",
        "outputId": "629e9ebe-cdcd-499a-fb39-92149542981d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Import the Universal Sentence Encoder's TF Hub module\n",
        "embed = hub.Module(module_url)\n",
        "embed_size = embed.get_output_info_dict()['default'].get_shape()[1].value"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gLsW4_Jr7zOJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#sentence_labels = utils.flatten([['AE N D'], ['S T AH', 'B ER N'], ['B R AE S'], ['AE N D'], ['T IH N'], ['AE N D'], ['S AA', 'L AH D'], ['G OW L D']])\n",
        "#other_sentence = utils.flatten([['T UW'], ['M IY'], ['IH T'], ['F L OW Z'], ['AH'], ['S AH', 'L AH N'], ['S T R IY M'], ['AH V'], ['T EH R Z']])\n",
        "#third_sentence = utils.flatten([['DH AH'], ['N OW', 'B AH L'], ['S IY', 'M AH N'], ['HH UW'], ['W IH TH', 'HH EH L D'], ['DH AH'], ['HH AE N D']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FwAQNy1eMDkQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# read classified poetry lines: text tab [['syll', 'la', 'ble'], ...]\n",
        "# clip to only most common syllables with syllable manager\n",
        "def get_data(filename, syll_mgr, num_symbols):\n",
        "    lines = open(filename, 'r').read().splitlines()\n",
        "    text_lines = []\n",
        "    enc_array = []\n",
        "    num_syllables = syll_mgr.get_size()\n",
        "    for i in range(0, len(lines)):\n",
        "      parts = lines[i].split(\"\\t\")\n",
        "      label = utils.flatten(literal_eval(parts[1]))\n",
        "      if len(label) != num_symbols:\n",
        "        continue\n",
        "      enc = np.zeros((num_symbols * syll_mgr.get_size()), dtype=np.int8)\n",
        "      for j in range(num_symbols):\n",
        "        enc[num_syllables * j + syll_mgr.get_encoding(label[j])] = 1\n",
        "      text_lines.append([parts[0]])\n",
        "      enc_array.append(enc)\n",
        "\n",
        "    return (np.array(text_lines), np.array(enc_array))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3HAtd4X5DayF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# syllables in descending order of occurrence - 6k in gutenberg.iambic_pentameter, 15k total\n",
        "# clamp to most common 100 syllables while debugging- use NCE to get all syllables or interesting number\n",
        "# 98 + pause + wildcard\n",
        "num_syllables = 1500 \n",
        "# iambic pentameter\n",
        "num_symbols = 10\n",
        "syll_mgr = syllables.syllables(num_syllables)\n",
        "\n",
        "# slow\n",
        "num_epochs = 20\n",
        "adam_0001 = tf.train.AdamOptimizer(0.0000005)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eN9aqig-QpDZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(train_text, train_label) = get_data('prepped_data/gutenberg.iambic_pentameter.train', syll_mgr, num_symbols)\n",
        "num_training = len(train_text)\n",
        "#train_text = train_text[0:10000]\n",
        "#train_label = train_label[0:10000]\n",
        "\n",
        "(test_text, test_label) = get_data('prepped_data/gutenberg.iambic_pentameter.test', syll_mgr, num_symbols)\n",
        "num_testing = len(test_text)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-mQUV_7dIm-9",
        "colab_type": "code",
        "outputId": "c9290290-9d02-434c-8f0d-f73d0d6d0378",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(2):\n",
        "  print(train_text[i][0])\n",
        "  print(train_label[i])\n",
        "  syll_mgr.interpret2(train_label[i])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "And stubborn brass, and tin, and solid gold;\n",
            "[0 0 0 ... 0 0 0]\n",
            "[7, 38, 343, 0, 7, 0, 7, 77, 78, 114]\n",
            "['AE N D', 'S T AH', 'B ER N', '?', 'AE N D', '?', 'AE N D', 'S AA', 'L AH D', 'G OW L D']\n",
            "To me, it flows a sullen stream of tears.\n",
            "[0 0 0 ... 0 0 0]\n",
            "[30, 59, 231, 0, 36, 175, 937, 0, 40, 977]\n",
            "['T UW', 'M IY', 'IH T', '?', 'AH', 'S AH', 'L AH N', '?', 'AH V', 'T EH R Z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ukpQVkEN1e_q",
        "colab_type": "code",
        "outputId": "5a2f06ca-3388-4625-eed7-43d17934d78e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "messages = []\n",
        "for i in range(200):\n",
        "  messages.append(train_text[i][0])\n",
        "with tf.Session() as session:\n",
        "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "  message_embeddings = session.run(embed(messages))\n",
        "predicts = message_embeddings"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7EiWYaaoryJV",
        "colab_type": "code",
        "outputId": "84eda98f-80ee-45c4-f3eb-7731998ed7ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "predicts = message_embeddings\n",
        "print(len(predicts))\n",
        "first = predicts[0]\n",
        "for i in range(len(predicts) - 1):\n",
        "  v = predicts[i]\n",
        "  #print(scipy.spatial.distance.cosine(v, first))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Sf9A4Xl6J7c6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Wrap embed module in a Lambda layer\n",
        "Explicitly cast the input as a string"
      ]
    },
    {
      "metadata": {
        "id": "PRD3fWgJjOrP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def UniversalEmbedding(x):\n",
        "    return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qX2rBOuxDP1m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Assemble model"
      ]
    },
    {
      "metadata": {
        "id": "t3fllZkVjXKV",
        "colab_type": "code",
        "outputId": "bafdf7f8-2056-4cc3-c1f5-9bcd0beee611",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "cell_type": "code",
      "source": [
        "# changed accuracy from 'choose your own accuracy'\n",
        "input_text = layers.Input(shape=(1,), dtype=tf.string)\n",
        "embedding = layers.Lambda(UniversalEmbedding, output_shape=(embed_size,))(input_text)\n",
        "dense = layers.Dense(1024, activation='relu')(embedding)\n",
        "pred = layers.Dense(num_syllables * num_symbols, activation='sigmoid')(dense)\n",
        "model = Model(inputs=[input_text], outputs=pred)\n",
        "model.compile(loss='binary_crossentropy', optimizer=adam_0001, metrics=['sparse_categorical_accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "lambda_1 (Lambda)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              2101248   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 15000)             61455000  \n",
            "=================================================================\n",
            "Total params: 63,556,248\n",
            "Trainable params: 63,556,248\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9PfsPdG8FZBI",
        "colab_type": "code",
        "outputId": "80483b51-3c9c-49be-87d9-c62dc1ba1c42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test_label.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4200, 15000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "gPYVmBr2Fbob",
        "colab_type": "code",
        "outputId": "48920910-e058-4567-9b6b-f47c1dd2b7ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "print(test_text[200])\n",
        "syll_mgr.interpret2(test_label[200])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['In this: whatever other blunders lie']\n",
            "[67, 224, 213, 65, 47, 36, 280, 0, 487, 901]\n",
            "['IH N', 'DH IH S', 'W AH T', 'EH', 'V ER', 'AH', 'DH ER', '?', 'D ER Z', 'L AY']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bqcRy_JWXe0u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train Keras model and save weights\n",
        "This only trains and save our Keras layers not the embed module' weights."
      ]
    },
    {
      "metadata": {
        "id": "_stfC_7VFhS8",
        "colab_type": "code",
        "outputId": "6c49f613-39e4-4a2c-dde6-a27f6176242c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1383
        }
      },
      "cell_type": "code",
      "source": [
        "if not os.path.exists('./model.h5'):\n",
        "  with tf.Session() as session:\n",
        "    K.set_session(session)\n",
        "    session.run(tf.global_variables_initializer())\n",
        "    session.run(tf.tables_initializer())\n",
        "    history = model.fit(train_text, \n",
        "            train_label,\n",
        "            validation_data=(test_text, test_label),\n",
        "            epochs=num_epochs,\n",
        "            batch_size=32)\n",
        "    model.save_weights('./model.h5')\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 58498 samples, validate on 4200 samples\n",
            "Epoch 1/20\n",
            "41568/58498 [====================>.........] - ETA: 40s - loss: 0.6926 - sparse_categorical_accuracy: 0.0000e+00"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-eac3cb1218c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             batch_size=32)\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "UW1CiBhnXnxa",
        "colab_type": "code",
        "outputId": "754f80e3-561b-459a-e28a-1ab28d37aa50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -alh | grep model.h5"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 243M Oct 24 07:44 model.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nQux6qLdXabG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Make predictions"
      ]
    },
    {
      "metadata": {
        "id": "fSDxetlfUEiD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#new_text = np.array(new_text, dtype=object)[:, np.newaxis]\n",
        "with tf.Session() as session:\n",
        "  K.set_session(session)\n",
        "  session.run(tf.global_variables_initializer())\n",
        "  session.run(tf.tables_initializer())\n",
        "  model.load_weights('./model.h5')  \n",
        "  predicts = model.predict(test_text, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U9V5JOWGq4Cd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c489f87c-806c-466e-8bf9-240b9963fa38"
      },
      "cell_type": "code",
      "source": [
        "first = predicts[0]\n",
        "max_d = -1000000\n",
        "min_d = 1000000\n",
        "max_i = 0\n",
        "min_i = 0\n",
        "for i in range(len(predicts) - 1):\n",
        "  v = predicts[i]\n",
        "  d = scipy.spatial.distance.cosine(v, first)\n",
        "  if max_d < d:\n",
        "    max_d = d\n",
        "    max_i = i\n",
        "  if min_d > d:\n",
        "    min_d = d\n",
        "    min_i = i\n",
        "print(\"Min and max distances: {0} and {1}\".format(min_d, max_d))"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Min and max distances: -4.907563178058183e-08 and 2.8883001750745763e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xaR0d5VPU23Z",
        "colab_type": "code",
        "outputId": "74db69a3-3434-4e91-f1f5-d25df77084f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        }
      },
      "cell_type": "code",
      "source": [
        "syll_mgr.interpret2(predicts[max_i])\n",
        "for i in range(10):\n",
        "  print(test_text[i])\n",
        "  print(predicts[i])\n",
        "  syll_mgr.interpret2(predicts[i])"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1429, 1293, 695, 1259, 128, 443, 997, 988, 187, 852]\n",
            "['F R AO D', 'HH Y UW N', 'K Y UW B', 'K OW P', 'AH L', 'B EH L', 'Y AH NG', 'L IH SH', 'K L EY M', 'F AO R S']\n",
            "['To life, the creamy onyx and the skins']\n",
            "[0.48644406 0.4891513  0.48640507 ... 0.48797417 0.48611757 0.48469386]\n",
            "[1114, 1293, 1296, 431, 963, 645, 1034, 969, 570, 1200]\n",
            "['OW TH', 'HH Y UW N', 'F Y UH', 'S T UW P', 'M AH T', 'G OW L', 'F AO R M', 'JH ER', 'V AH N', 'D EH V']\n",
            "['And what is Man the while? And what his will?']\n",
            "[0.49001873 0.49415073 0.48510784 ... 0.49021637 0.48950568 0.48458475]\n",
            "[195, 313, 857, 774, 176, 860, 325, 618, 234, 237]\n",
            "['R IH', 'Z AY N', 'G R AE S', 'L IH NG Z', 'M ER Z', 'G AE', 'T IH D', 'S K W EH R', 'V EH N', 'P ER']\n",
            "['Of startled grasses, and the hedge in bloom,--']\n",
            "[0.48931998 0.49049613 0.4831991  ... 0.48727813 0.48540083 0.47938696]\n",
            "[1114, 217, 1007, 1440, 963, 98, 1050, 969, 178, 748]\n",
            "['OW TH', 'P R EH', 'K L AE', 'G EY Z', 'M AH T', 'ER Z', 'W AA', 'JH ER', 'S EH', 'L EY K S']\n",
            "['The match was offered, the proposals made']\n",
            "[0.4907124  0.49094757 0.4904624  ... 0.4905775  0.4907515  0.48553142]\n",
            "[445, 1083, 695, 1440, 261, 98, 1487, 1337, 187, 1195]\n",
            "['HH EH D', 'B AH L D', 'K Y UW B', 'G EY Z', 'T ER Z', 'ER Z', 'JH OY S', 'R OW L D', 'K L EY M', 'S T R IH']\n",
            "['Were landed in the market, one and all,']\n",
            "[0.4869792  0.48827112 0.48839432 ... 0.4923341  0.488455   0.48781243]\n",
            "[455, 827, 695, 1440, 187, 186, 176, 430, 669, 1442]\n",
            "['K AH M', 'F R EH N D', 'K Y UW B', 'G EY Z', 'K L EY M', 'P R OW', 'M ER Z', 'M AH JH', 'D R AY V', 'B L AY DH']\n",
            "['The vale of Nature, where it creeps and winds']\n",
            "[0.48686013 0.4913976  0.48644158 ... 0.48867825 0.48837787 0.48222783]\n",
            "[1114, 1439, 164, 1324, 72, 98, 295, 846, 34, 65]\n",
            "['OW TH', 'T IY T S', 'B EH N T', 'T AY R D', 'TH R UW', 'ER Z', 'L EH F T', 'F UW D', 'SH AH N', 'EH']\n",
            "['And Bacchus city had become enthralled,']\n",
            "[0.4878719  0.48779106 0.4875746  ... 0.4898176  0.48895365 0.4816478 ]\n",
            "[455, 1439, 401, 863, 122, 1050, 295, 415, 1129, 1011]\n",
            "['K AH M', 'T IY T S', 'JH AH N', 'B R UW', 'F R EY', 'W AA', 'L EH F T', 'P EH N', 'S T EH N D', 'AH N T S']\n",
            "['The marks of seasons wild and winters bleak']\n",
            "[0.48783553 0.48882678 0.48640975 ... 0.48883897 0.4888215  0.4836439 ]\n",
            "[1114, 563, 929, 1057, 230, 645, 1034, 982, 930, 65]\n",
            "['OW TH', 'L EH', 'HH AO', 'CH UW Z', 'TH R OW N', 'G OW L', 'F AO R M', 'F IY S T', 'T R AE N', 'EH']\n",
            "['That in the sunshine floats, beneath the blue,']\n",
            "[0.49043867 0.4930851  0.489166   ... 0.49011362 0.48916292 0.4881916 ]\n",
            "[1321, 313, 517, 1324, 963, 90, 1034, 390, 669, 65]\n",
            "['G R EY N', 'Z AY N', 'D IY L Z', 'T AY R D', 'M AH T', 'HH EH L', 'F AO R M', 'V IH L', 'D R AY V', 'EH']\n",
            "['His burning idol all of blackest hue:']\n",
            "[0.49028587 0.48738435 0.48499402 ... 0.48693016 0.4876728  0.4842018 ]\n",
            "[251, 448, 1296, 356, 515, 816, 325, 1423, 952, 549]\n",
            "['D AE SH', 'T AH', 'F Y UH', 'W AO', 'N Y AH N', 'HH AE TH', 'T IH D', 'S W IY', 'B IH K', 'N IH SH']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yyDGVtigW57f",
        "colab_type": "code",
        "outputId": "4d792958-209a-4ea3-9bc4-306003240c75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "cell_type": "code",
      "source": [
        "categories = df_train.label.cat.categories.tolist()\n",
        "predict_logits = predicts.argmax(axis=1)\n",
        "print(\"Categorie: {0}\".format(categories))\n",
        "predict_labels = [categories[logit] for logit in predict_logits]\n",
        "predict_labels"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-147-7f6e6bf5580f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredict_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Categorie: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredict_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlogit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredict_logits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredict_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "hYhmukbSKpnp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "os.remove('./model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}