{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Meter: Keras + Universal Sentence Encoder + CMUdict + Project Gutenberg poetry archives",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "co7MV6sX7Xto",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# [Keras + Universal Sentence Encoder = Deep Meter](https://www.dlology.com/blog/keras-meets-universal-sentence-encoder-transfer-learning-for-text-data/) "
      ]
    },
    {
      "metadata": {
        "id": "eAVQGidpL8v5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook creates an autoencoder using the Universal Sentence Encoder. The autoencoder output is CMUdict syllables. The dataset is that subset of Allison Parrish's Project Gutenberg poetry archive which happens to scan in iambic pentameter.\n",
        "\n",
        "The notebook is based on Chengwei Zhang's example of wrapping the USE inside a larger tensorflow model saves to a Keras model (without save the USE itself in the TF model).\n",
        "\n",
        "The Universal Sentence Encoder makes getting sentence level embeddings as easy as it has historically been to lookup the embeddings for individual words. The sentence embeddings can then be trivially used to compute sentence level meaning similarity as well as to enable better performance on downstream classification tasks using less supervised training data.\n",
        "\n",
        "Since there are 10 one-hot values for 10 sets of 6k syllables, this is \"multi-label classification\"\n",
        "Changes for multi-label classification:\n",
        "sigmoid activation instead of softmax\n",
        "binary_crossentropy\n",
        "\n",
        "Text format is tab-separated, 2 columns: first text, second multi-level\n",
        "array of syllables:\n"
      ]
    },
    {
      "metadata": {
        "id": "pOTzp8O36CyQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Getting Started\n",
        "\n",
        "This section sets up the environment for access to the Universal Sentence Encoder on TF Hub and provides examples of applying the encoder to words, sentences, and paragraphs."
      ]
    },
    {
      "metadata": {
        "id": "lVjNK8shFKOC",
        "colab_type": "code",
        "outputId": "e45b1599-8eca-4140-8c52-fab662355e6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "cell_type": "code",
      "source": [
        "# Install the latest Tensorflow version.\n",
        "!pip3 install --quiet \"tensorflow>=1.7\"\n",
        "# Install TF-Hub.\n",
        "!pip3 install --quiet tensorflow-hub\n",
        "%cd /content\n",
        "!git clone https://github.com/LanceNorskog/deep_meter || true\n",
        "%cd deep_meter\n",
        "!git pull\n",
        "# could not figure out how to read gzipped files as text!\n",
        "!gunzip -qf blobs/*.gz || true\n",
        "!gunzip -qf prepped_data/*.gz || true"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'deep_meter'...\n",
            "remote: Enumerating objects: 175, done.\u001b[K\n",
            "remote: Counting objects: 100% (175/175), done.\u001b[K\n",
            "remote: Compressing objects: 100% (123/123), done.\u001b[K\n",
            "remote: Total 175 (delta 90), reused 127 (delta 45), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (175/175), 20.67 MiB | 31.79 MiB/s, done.\n",
            "Resolving deltas: 100% (90/90), done.\n",
            "/content/deep_meter\n",
            "Already up to date.\n",
            "gzip: blobs/*.gz: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MSeY-MUQo2Ha",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns\n",
        "import keras.layers as layers\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "np.random.seed(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "feBc_8Y-pt6F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import syllables\n",
        "from itertools import chain\n",
        "from ast import literal_eval\n",
        "from sklearn.preprocessing import MultiLabelBinarizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zwty8Z6mAkdV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q8F4LNGFqOiq",
        "colab_type": "code",
        "outputId": "30774a6b-2bd9-422a-f8c4-6e7f66d3cffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "# Import the Universal Sentence Encoder's TF Hub module\n",
        "embed = hub.Module(module_url)\n",
        "embed_size = embed.get_output_info_dict()['default'].get_shape()[1].value"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n",
            "INFO:tensorflow:Downloading TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder-large/3'.\n",
            "INFO:tensorflow:Downloaded TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder-large/3'.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lNRSk5lukD_u",
        "colab_type": "code",
        "outputId": "b104afd8-5b13-4413-8bc2-073c2041432d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "# Compute a representation for each message, showing various lengths supported.\n",
        "f = open(\"prepped_data/gutenberg.iambic_pentameter\")\n",
        "line = f.readline().split(\"\\t\")[0]\n",
        "print(line)\n",
        "messages = [line]\n",
        "\n",
        "with tf.Session() as session:\n",
        "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "  message_embeddings = session.run(embed(messages))\n",
        "message_embeddings[0][:3]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From their Creator, and transgress his Will\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.09510787, 0.01377319, 0.0609108 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "gLsW4_Jr7zOJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def flatten(data):\n",
        "  return list(chain.from_iterable(data))\n",
        "train_text_raw = []\n",
        "train_labels_raw = []\n",
        "with open(\"prepped_data/gutenberg.iambic_pentameter.train\") as file:\n",
        "  for line in file:\n",
        "    parts = line.split(\"\\t\")\n",
        "    train_text_raw += [parts[0]]\n",
        "    train_labels_raw += [flatten(literal_eval(parts[1]))]\n",
        "    \n",
        "num_training = len(train_text_raw)\n",
        "    \n",
        "sentence_labels = flatten([['AE N D'], ['S T AH', 'B ER N'], ['B R AE S'], ['AE N D'], ['T IH N'], ['AE N D'], ['S AA', 'L AH D'], ['G OW L D']])\n",
        "other_sentence = flatten([['T UW'], ['M IY'], ['IH T'], ['F L OW Z'], ['AH'], ['S AH', 'L AH N'], ['S T R IY M'], ['AH V'], ['T EH R Z']])\n",
        "third_sentence = flatten([['DH AH'], ['N OW', 'B AH L'], ['S IY', 'M AH N'], ['HH UW'], ['W IH TH', 'HH EH L D'], ['DH AH'], ['HH AE N D']])\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xT7DK3jNjq98",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "3HAtd4X5DayF",
        "colab_type": "code",
        "outputId": "b78baac1-9e38-4487-f820-b3c541a36e3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# syllables in descending order of occurrence - 6k in gutenberg.iambic_pentameter, 15k total\n",
        "# clamp to most common 100 syllables while debugging- use NCE to get all syllables or interesting number\n",
        "# 98 + pause + wildcard\n",
        "num_syllables = 100 \n",
        "# iambic pentameter\n",
        "num_symbols = 10\n",
        "syll_mgr = syllables.syllables(num_syllables)\n",
        "train_labels_encoded = np.zeros((num_training, num_symbols * num_syllables))\n",
        "fail_i = 0\n",
        "fail_j = 0\n",
        "fail_enc = 0\n",
        "for i in range(num_training):\n",
        "  fail_i = i\n",
        "  if len(train_labels_raw[i]) != 10:\n",
        "    continue\n",
        "  for j in range(num_symbols):\n",
        "    fail_j = j\n",
        "    fail_enc = -1\n",
        "    fail_enc = syll_mgr.get_encoding(train_labels_raw[i][j])\n",
        "    train_labels_encoded[i][j * num_syllables + syll_mgr.get_encoding(train_labels_raw[i][j])] = 1\n",
        "  \n",
        "print(train_labels_encoded.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(62320, 1000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Sf9A4Xl6J7c6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Wrap embed module in a Lambda layer\n",
        "Explicitly cast the input as a string"
      ]
    },
    {
      "metadata": {
        "id": "PRD3fWgJjOrP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def UniversalEmbedding(x):\n",
        "    return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qX2rBOuxDP1m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Assemble model"
      ]
    },
    {
      "metadata": {
        "id": "t3fllZkVjXKV",
        "colab_type": "code",
        "outputId": "cd7113f4-dd67-4188-aed9-0352261ce33b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "cell_type": "code",
      "source": [
        "input_text = layers.Input(shape=(1,), dtype=tf.string)\n",
        "embedding = layers.Lambda(UniversalEmbedding, output_shape=(embed_size,))(input_text)\n",
        "dense = layers.Dense(512, activation='relu')(embedding)\n",
        "pred = layers.Dense(num_syllables * num_symbols, activation='sigmoid')(dense)\n",
        "model = Model(inputs=[input_text], outputs=pred)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "lambda_1 (Lambda)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1000)              513000    \n",
            "=================================================================\n",
            "Total params: 775,656\n",
            "Trainable params: 775,656\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5Ube1DvYEJ3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "ba8002fc-dff3-4944-bd5d-3da0f4fc88c7"
      },
      "cell_type": "code",
      "source": [
        "train_text = df_train['text'].tolist()\n",
        "train_text = np.array(train_text, dtype=object)[:, np.newaxis]\n",
        "\n",
        "train_label = np.asarray(pd.get_dummies(df_train.label), dtype = np.int8)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-27576113950c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "WX3s8yIVFWHI",
        "colab_type": "code",
        "outputId": "aadb0d89-e2d7-42e4-ba5f-a4b342fec782",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_text.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "9PfsPdG8FZBI",
        "colab_type": "code",
        "outputId": "f0761e82-3826-4c74-9128-d8593a7cfc6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_label.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "gPYVmBr2Fbob",
        "colab_type": "code",
        "outputId": "a50dc6b8-6cff-4db1-c694-e64cd89b2be1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "train_label[:3]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 1, 0],\n",
              "       [0, 0, 0, 1, 0, 0]], dtype=int8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "X9MJnOnKI6F0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_test = get_dataframe('test_data.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QWAjtjdeI9P4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_text = df_test['text'].tolist()\n",
        "test_text = np.array(test_text, dtype=object)[:, np.newaxis]\n",
        "test_label = np.asarray(pd.get_dummies(df_test.label), dtype = np.int8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bqcRy_JWXe0u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train Keras model and save weights\n",
        "This only train and save our Keras layers not the embed module' weights."
      ]
    },
    {
      "metadata": {
        "id": "_stfC_7VFhS8",
        "colab_type": "code",
        "outputId": "48e3e5c8-41d4-40a9-d18b-1f527cf937e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as session:\n",
        "  K.set_session(session)\n",
        "  session.run(tf.global_variables_initializer())\n",
        "  session.run(tf.tables_initializer())\n",
        "  history = model.fit(train_text, \n",
        "            train_label,\n",
        "            validation_data=(test_text, test_label),\n",
        "            epochs=10,\n",
        "            batch_size=32)\n",
        "  model.save_weights('./model.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 500 samples, validate on 500 samples\n",
            "Epoch 1/10\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 1.5877 - acc: 0.5720 - val_loss: 1.3012 - val_acc: 0.7800\n",
            "Epoch 2/10\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 1.0911 - acc: 0.8080 - val_loss: 0.8441 - val_acc: 0.8560\n",
            "Epoch 3/10\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.7137 - acc: 0.8820 - val_loss: 0.5658 - val_acc: 0.8980\n",
            "Epoch 4/10\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.4974 - acc: 0.8940 - val_loss: 0.4195 - val_acc: 0.9040\n",
            "Epoch 5/10\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.3882 - acc: 0.9100 - val_loss: 0.3359 - val_acc: 0.9240\n",
            "Epoch 6/10\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.3145 - acc: 0.9200 - val_loss: 0.2817 - val_acc: 0.9300\n",
            "Epoch 7/10\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.2694 - acc: 0.9280 - val_loss: 0.2392 - val_acc: 0.9400\n",
            "Epoch 8/10\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.2313 - acc: 0.9440 - val_loss: 0.2081 - val_acc: 0.9440\n",
            "Epoch 9/10\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.2005 - acc: 0.9460 - val_loss: 0.1811 - val_acc: 0.9560\n",
            "Epoch 10/10\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.1763 - acc: 0.9620 - val_loss: 0.1595 - val_acc: 0.9640\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UW1CiBhnXnxa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls -alh | grep model.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nQux6qLdXabG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Make predictions"
      ]
    },
    {
      "metadata": {
        "id": "fSDxetlfUEiD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "new_text = [\"In what year did the titanic sink ?\", \"What is the highest peak in California ?\", \"Who invented the light bulb ?\"]\n",
        "new_text = np.array(new_text, dtype=object)[:, np.newaxis]\n",
        "with tf.Session() as session:\n",
        "  K.set_session(session)\n",
        "  session.run(tf.global_variables_initializer())\n",
        "  session.run(tf.tables_initializer())\n",
        "  model.load_weights('./model.h5')  \n",
        "  predicts = model.predict(new_text, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xaR0d5VPU23Z",
        "colab_type": "code",
        "outputId": "1172818f-b579-4b13-f7e8-cc0a6c61226b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "predicts"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.4159707e-05, 6.0455163e-04, 8.8598131e-04, 7.6786731e-05,\n",
              "        4.0342723e-04, 9.9794513e-01],\n",
              "       [1.6934730e-03, 2.2273099e-03, 2.4022337e-02, 2.4095874e-03,\n",
              "        6.6579401e-01, 3.0385330e-01],\n",
              "       [5.7516660e-04, 9.6968655e-04, 4.5365933e-02, 9.5041847e-01,\n",
              "        2.1153719e-03, 5.5547140e-04]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "yyDGVtigW57f",
        "colab_type": "code",
        "outputId": "004e4134-7446-4555-a8e6-101bb36c0b1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "categories = df_train.label.cat.categories.tolist()\n",
        "predict_logits = predicts.argmax(axis=1)\n",
        "print(\"Categorie: {0}\".format(categories))\n",
        "predict_labels = [categories[logit] for logit in predict_logits]\n",
        "predict_labels"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Categories: ['ABBR', 'DESC', 'ENTY', 'HUM', 'LOC', 'NUM']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NUM', 'LOC', 'HUM']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "hYhmukbSKpnp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}